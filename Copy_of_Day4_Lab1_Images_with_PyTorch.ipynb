{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Lamjj1/Files/blob/main/Copy_of_Day4_Lab1_Images_with_PyTorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kPzUOet7lRk4"
      },
      "source": [
        "![image.png](https://i.imgur.com/a3uAqnb.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3u2kk8K1cjcr"
      },
      "source": [
        "# ðŸ§  **Neural Networks with PyTorch: MNIST Classification**\n",
        "---\n",
        "\n",
        "In this lab, we will:\n",
        "- Use **built-in dataset** of images such as **MNIST**\n",
        "- Build a model class of **three-layer neural network classifier** using PyTorch\n",
        "- Train the model and evaluate its performance on test data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "igtt7JEPk6-c"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision.datasets import MNIST\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.optim import Adam\n",
        "from torchvision.transforms.functional import to_tensor\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FXBDl29AhTh1"
      },
      "source": [
        "## ðŸ“Š **About MNIST**\n",
        "\n",
        "\n",
        "<img src=\"https://s3.w3s.aioz.network/w3ai-platform-v2/uploads/documents/54deb202-59ab-491b-b167-e0d95f9c4eb7/2024/06/24/1719218079-39fPyGLN53MiaRknDk8wCe.png?AWSAccessKeyId=FT7EO3IGQNMIILHXIDZRVTJHWE&Signature=HlOvnFSFw2T9o7yc2Xp3qfbb3Ao%3D&Expires=2349938079\" width=\"50%\">\n",
        "\n",
        "MNIST is a **built-in** dataset of **grayscale handwritten digit images (0â€“9)**.\n",
        "\n",
        "The dataset contains **60,000 training images** and **10,000 testing images**, each of size **28 Ã— 28 pixels**.\n",
        "\n",
        "**know how to use custom classes and create them **\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s2e6OqRYjFIp"
      },
      "source": [
        "### ðŸ”¹**Prepare Data**\n",
        "\n",
        "\n",
        "> We load the MNIST dataset by creating separate **training** and **testing** dataset objects and applying a tensor transformation to each image.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gx5Hu2ffjko-",
        "outputId": "823f1040-3062-4631-af98-0eef62030034"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9.91M/9.91M [00:00<00:00, 18.1MB/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 28.9k/28.9k [00:00<00:00, 483kB/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.65M/1.65M [00:00<00:00, 4.51MB/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4.54k/4.54k [00:00<00:00, 13.6MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Image shape: torch.Size([1, 28, 28])\n",
            "Label: 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Training dataset\n",
        "train_dataset = MNIST(\n",
        "    root='./datasets',     # Dataset storage path , where u want to srote ur dataset\n",
        "    train=True,            # Use training data, train split not test splits\n",
        "    transform=to_tensor,   # Convert images to tensors\n",
        "    download=True          # Download if not available. just mark it as True\n",
        ")\n",
        "\n",
        "# Testing dataset\n",
        "test_dataset = MNIST(\n",
        "    root='./datasets',     # Dataset storage path\n",
        "    train=False,           # Use test data\n",
        "    transform=to_tensor,   # Convert images to tensors\n",
        "    download=True          # Download if not available\n",
        ")\n",
        "\n",
        "# print one sample from the dataset\n",
        "# Each sample consists of an image tensor and its label\n",
        "sample_image, sample_label = train_dataset[0]\n",
        "\n",
        "print(f\"\\n Image shape: {sample_image.shape}\")  # (1, 28, 28) 1 from the channel , you can squees=ze it\n",
        "print(f\"Label: {sample_label}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CQ2zUIcb0ilh"
      },
      "source": [
        "\n",
        "\n",
        "> We use **DataLoaders** to group the training and testing datasets into mini-batches and feed them efficiently to the model during training and evaluation.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VY7-N1hSznDR",
        "outputId": "da936190-e6f0-4384-b40a-8a93c65010db"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training batch input shape: torch.Size([32, 1, 28, 28])\n",
            "Training batch labels shape: torch.Size([32])\n"
          ]
        }
      ],
      "source": [
        "# DataLoader for training data\n",
        "train_loader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=32,\n",
        "    shuffle=True,\n",
        "    num_workers=2 # numbers of cores inside cpu , know what it does and where to put it, 0 means look for how many u have (default)\n",
        ")\n",
        "# DataLoader for test/validation data\n",
        "test_loader = DataLoader(\n",
        "    test_dataset,\n",
        "    batch_size=32,\n",
        "    shuffle=False,\n",
        "    num_workers=2\n",
        ")\n",
        "# Get the first batch from the training DataLoader\n",
        "X_batch, y_batch = next(iter(train_loader))\n",
        "print(f\"Training batch input shape: {X_batch.shape}\")\n",
        "print(f\"Training batch labels shape: {y_batch.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0QawNKMJ0xPf"
      },
      "source": [
        "\n",
        "\n",
        "> Lets display some images !\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "id": "8cfXi8nF01yd",
        "outputId": "a5532576-5166-436d-e130-bc79961e5293"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x400 with 6 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Get one batch of images and labels, copy pastable\n",
        "images, labels = next(iter(train_loader))\n",
        "\n",
        "# Display the first 6 images in the batch\n",
        "plt.figure(figsize=(8, 4))\n",
        "\n",
        "for i in range(6):\n",
        "    plt.subplot(2, 3, i + 1)\n",
        "    plt.imshow(images[i].squeeze(), cmap='gray')\n",
        "    plt.title(f\"Label: {labels[i].item()}\")\n",
        "    plt.axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JrGL0vog1Rni"
      },
      "source": [
        "\n",
        "\n",
        "> Data now is ready for the model ! Lets build the model class.\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eJ0Vhxkv1ufi"
      },
      "source": [
        "### ðŸ”¹**Model Class**\n",
        "\n",
        "\n",
        "Letâ€™s create the **architecture of our model** by implementing a **three-layer neural network classifier**.\n",
        "\n",
        "Instead of **sigmoid**, we use **softmax** at the output layer:\n",
        "- **Sigmoid** outputs values in the range (0, 1)\n",
        "- **Softmax** converts a vector into probabilities that sum to 1\n",
        "\n",
        "Softmax formula: $$\\text{Softmax}(x)_i = \\frac{e^{x_i}}{\\sum_{j} e^{x_j}}$$\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "VSPjlvRF1tiq"
      },
      "outputs": [],
      "source": [
        "class NN3Layer(nn.Module):\n",
        "\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
        "        super(NN3Layer, self).__init__()\n",
        "\n",
        "        # First linear layer: input features -> hidden layer\n",
        "        self.layer1 = nn.Linear(input_dim, hidden_dim)\n",
        "\n",
        "        # Second linear layer: hidden layer -> hidden layer\n",
        "        self.layer2 = nn.Linear(hidden_dim, hidden_dim)\n",
        "\n",
        "        # Output layer: hidden layer -> number of classes (logits)\n",
        "        self.layer3 = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "        # ReLU activation for non-linearity\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    # Defines how input data flows through the network\n",
        "    def forward(self, x):\n",
        "        # First hidden layer\n",
        "        z1 = self.layer1(x)\n",
        "        a1 = self.relu(z1)\n",
        "\n",
        "        # Second hidden layer\n",
        "        z2 = self.layer2(a1)\n",
        "        a2 = self.relu(z2)\n",
        "\n",
        "        # Output layer (raw scores / logits)\n",
        "        output = self.layer3(a2) # there is something missing here, remember? :) op does not need an activation function\n",
        "\n",
        "        return output\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1P1IBJA35dU6"
      },
      "source": [
        "ðŸ“Œ **Note on Softmax**\n",
        "\n",
        "The output of this model consists of **raw scores (logits)**, not probabilities.  \n",
        "When using `CrossEntropyLoss`, **Softmax is applied internally**, so it should **not** be included in the modelâ€™s architecture.\n",
        "\n",
        "Softmax can be applied **only during evaluation** if class probabilities are needed.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jSf7tqF46B-J"
      },
      "source": [
        "### ðŸ”¹**Training Loop**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "80HwDB3x6UQq"
      },
      "outputs": [],
      "source": [
        "def train_one_epoch(model, optimizer, criterion, train_loader, device):\n",
        "    # Set the model to training mode\n",
        "    model.train()\n",
        "\n",
        "    running_loss = 0.0\n",
        "\n",
        "    for X_batch, y_batch in train_loader:\n",
        "        # Move batch to the selected device\n",
        "        X_batch = X_batch.view(X_batch.size(0), -1).to(device) #very important step, it flatten the pic , u can use flatten here instead\n",
        "        y_batch = y_batch.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(X_batch) # shape: (batch_size, 10)\n",
        "        loss = criterion(outputs, y_batch)\n",
        "\n",
        "        # Backward pass & optimization\n",
        "        optimizer.zero_grad()   # Clear previous gradients, zero it out\n",
        "        loss.backward()         # Compute gradients\n",
        "        optimizer.step()        # Update model parameters\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    # Average loss over all batches\n",
        "    avg_loss = running_loss / len(train_loader) # loss / num of batchs\n",
        "\n",
        "    return avg_loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gCsSeUJ962d4"
      },
      "source": [
        "### ðŸ”¹**Validation Loop**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "srnAVul266gi"
      },
      "outputs": [],
      "source": [
        "def validate(model, criterion, test_loader, device):\n",
        "    # Set the model to evaluation mode\n",
        "    model.eval()\n",
        "\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for X_batch, y_batch in test_loader:\n",
        "            # Move data to device\n",
        "            X_batch = X_batch.view(X_batch.size(0), -1).to(device)\n",
        "            y_batch = y_batch.to(device)\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(X_batch)  # shape: (batch_size, 10)\n",
        "            loss = criterion(outputs, y_batch)\n",
        "            running_loss += loss.item()\n",
        "\n",
        "            # Apply Softmax to get probabilities\n",
        "            probabilities = F.softmax(outputs, dim=1) # dim 1 is do prob based on classes\n",
        "\n",
        "            # Multiclass predictions\n",
        "            predicted = torch.argmax(probabilities, dim=1) #maximim prob (indexes thats why argmax)\n",
        "\n",
        "            # Accuracy calculation\n",
        "            correct += (predicted == y_batch).sum().item()\n",
        "            total += y_batch.size(0) # num of samples\n",
        "\n",
        "    avg_loss = running_loss / len(test_loader)\n",
        "    accuracy = correct / total\n",
        "\n",
        "    return avg_loss, accuracy\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d5INB-VM9DKS"
      },
      "source": [
        "### ðŸ”¹**Running Training**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nk6GDqBD9KKr",
        "outputId": "28187122-0f83-409a-aa01-0d99151546bd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Architecture:\n",
            "\n",
            "NN3Layer(\n",
            "  (layer1): Linear(in_features=784, out_features=14, bias=True)\n",
            "  (layer2): Linear(in_features=14, out_features=14, bias=True)\n",
            "  (layer3): Linear(in_features=14, out_features=10, bias=True)\n",
            "  (relu): ReLU()\n",
            ")\n",
            "\n",
            "Total trainable parameters: 11350\n"
          ]
        }
      ],
      "source": [
        "# Device setup\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Model parameters\n",
        "input_dim = 28 * 28   # MNIST images flattened (vector)\n",
        "hidden_dim = 14      # Design choice\n",
        "output_dim = 10       # Digits 0â€“9 has to be number of dp\n",
        "\n",
        "# Instantiate model\n",
        "model = NN3Layer(input_dim, hidden_dim, output_dim).to(device)\n",
        "\n",
        "# Print the model architecture\n",
        "print(\"Model Architecture:\\n\")\n",
        "print(model)\n",
        "\n",
        "# Calculate the total number of trainable parameters, copy paste !!!\n",
        "total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print(f\"\\nTotal trainable parameters: {total_params}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "TcTLWvAZ-SNT"
      },
      "outputs": [],
      "source": [
        "num_epochs = 10\n",
        "learning_rate = 0.001\n",
        "\n",
        "# Define criterion (loss function) - using CrossEntropyLoss as model now outputs logits\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "# Define optimizer\n",
        "optimizer = Adam(model.parameters(), learning_rate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7gvwR7ST_N-w",
        "outputId": "4ce3b689-2cb5-4651-bc77-a1e574ea8554"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting Training...\n"
          ]
        }
      ],
      "source": [
        "# Run Training\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "val_accuracies = []\n",
        "\n",
        "print('Starting Training...')\n",
        "for epoch in range(num_epochs):\n",
        "    # Train one epoch\n",
        "    train_loss = train_one_epoch(model, optimizer, criterion, train_loader, device)\n",
        "\n",
        "    # Validate\n",
        "    val_loss, val_accuracy = validate(model, criterion, test_loader, device)\n",
        "\n",
        "    train_losses.append(train_loss)\n",
        "    val_losses.append(val_loss)\n",
        "    val_accuracies.append(val_accuracy)\n",
        "\n",
        "    print(f'Epoch [{epoch+1}/{num_epochs}], Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.4f}')\n",
        "\n",
        "print('Training Complete!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yRBw8FYFB2xH"
      },
      "source": [
        "\n",
        "\n",
        "> Lets see what train and validation losses look like\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iChepqD9B-U0"
      },
      "outputs": [],
      "source": [
        "# Plotting results\n",
        "plt.figure(figsize=(7, 5))\n",
        "\n",
        "plt.plot(train_losses, label='Train Loss')\n",
        "plt.plot(val_losses, label='Validation Loss')\n",
        "plt.title('Loss over Epochs')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mz_XPYO7Gqxm"
      },
      "source": [
        "\n",
        "\n",
        "> lets plot some predictions from our model\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "egE9CpQ7GRRO"
      },
      "outputs": [],
      "source": [
        "# Set model to evaluation mode\n",
        "model.eval()\n",
        "# Get one batch from the test DataLoader\n",
        "images, labels = next(iter(test_loader))\n",
        "# Move images to device\n",
        "images = images.to(device)\n",
        "labels = labels.to(device)\n",
        "\n",
        "with torch.no_grad():\n",
        "    # Flatten images before passing to the model\n",
        "    outputs = model(images.view(images.size(0), -1))\n",
        "    predictions = torch.argmax(outputs, dim=1) #no softmax cuz we wanna pridect ***\n",
        "\n",
        "# Move tensors back to CPU for plotting, important\n",
        "images = images.cpu()\n",
        "labels = labels.cpu()\n",
        "predictions = predictions.cpu()\n",
        "\n",
        "# Plot first 6 predictions\n",
        "plt.figure(figsize=(8, 4))\n",
        "for i in range(6):\n",
        "    plt.subplot(2, 3, i + 1)\n",
        "    plt.imshow(images[i].squeeze(), cmap='gray')\n",
        "    plt.title(f\"True: {labels[i]} | Pred: {predictions[i]}\")\n",
        "    plt.axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eRmx8dK5HJJG"
      },
      "source": [
        "### ðŸ’¾ **Saving the Model**\n",
        "\n",
        "After training, we can save the model so it can be **reused later without retraining**.  \n",
        "In PyTorch, the recommended approach is to save the modelâ€™s **state dictionary**, which contains all learned parameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p7In-lVAHNYX"
      },
      "outputs": [],
      "source": [
        "# Save the trained model parameters\n",
        "torch.save(model.state_dict(), \"mnist_nn3layer.pth\")\n",
        "\n",
        "print(\"Model saved successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-cU444bZHToE"
      },
      "source": [
        "\n",
        "\n",
        "> if you want to use the model :\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "osgeLhePHTMQ"
      },
      "outputs": [],
      "source": [
        "# Recreate the model architecture\n",
        "model = NN3Layer(input_dim, hidden_dim, output_dim)\n",
        "# Load saved parameters\n",
        "model.load_state_dict(torch.load(\"mnist_nn3layer.pth\"))\n",
        "# Set model to evaluation mode\n",
        "model.eval()\n",
        "print(\"Model loaded successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SJ6HycG5IB7x"
      },
      "source": [
        "\n",
        "\n",
        "<img src=\"https://miro.medium.com/v2/resize:fit:1270/0*EmoDsauYmQMih_So\" width=\"30%\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "keKy5jBgzqqS"
      },
      "source": [
        "### **Contributed by: Yara Alzahrani**"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}