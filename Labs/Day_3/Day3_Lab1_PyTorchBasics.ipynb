{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KamP67nRt-Ko"
      },
      "source": [
        "![image.png](https://i.imgur.com/a3uAqnb.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eaRn1N6ZuHHg"
      },
      "source": [
        "#**Lab: Pytorch Basics**\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hZXwf7gKK_Ia"
      },
      "source": [
        "## **What is Pytorch?** <img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/1/10/PyTorch_logo_icon.svg/500px-PyTorch_logo_icon.svg.png\" width=\"4%\">\n",
        "\n",
        "\n",
        "**PyTorch** is an open-source deep learning framework that allows us to build and train neural networks using **tensors** and **automatic differentiation**.  \n",
        "It provides simple, flexible tools to define models, compute gradients using backpropagation, and optimize parameters efficiently.\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vMLes6srWwMe"
      },
      "source": [
        "## üì¶ **Tensors in PyTorch**\n",
        "\n",
        "A **tensor** is the main data structure in PyTorch.  \n",
        "It is similar to a NumPy array, but can run on both CPUs and GPUs.\n",
        "\n",
        "Tensors are used to represent: input data, model parameters, and model outputs\n",
        "\n",
        "### üîπ Creating Tensors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o_R5-1UJaw0w",
        "outputId": "7f40aae4-f374-4ec7-bdf3-1c04b5651e73"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x: tensor([1., 2., 3.])\n",
            "y: tensor([ 0.7126,  0.8889, -0.0984])\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "# Create tensors\n",
        "x = torch.tensor([1.0, 2.0, 3.0])\n",
        "y = torch.randn(3)\n",
        "print(\"x:\", x)\n",
        "print(\"y:\", y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1boO-_nua7dB"
      },
      "source": [
        "### üîπ Tensor Shapes\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6BDn9esxa_o_",
        "outputId": "540bbd93-1902-48b9-abe0-7060198f78c4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of x: torch.Size([3])\n"
          ]
        }
      ],
      "source": [
        "print(\"Shape of x:\", x.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jfrk3ELobLIP"
      },
      "source": [
        "### üîπ Tensor Operations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Krsxjc3bYqo",
        "outputId": "349a9a94-648d-4f10-dd2b-1d60f55266e2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Addition: tensor([5., 7., 9.])\n",
            "Multiplication: tensor([ 4., 10., 18.])\n",
            "Matrix multiplication result shape: torch.Size([2, 2])\n"
          ]
        }
      ],
      "source": [
        "a = torch.tensor([1.0, 2.0, 3.0])\n",
        "b = torch.tensor([4.0, 5.0, 6.0])\n",
        "\n",
        "# Element-wise operations\n",
        "print(\"Addition:\", a + b)\n",
        "print(\"Multiplication:\", a * b)\n",
        "\n",
        "# Matrix multiplication\n",
        "A = torch.randn(2, 3)\n",
        "B = torch.randn(3, 2)\n",
        "C = A @ B\n",
        "\n",
        "print(\"Matrix multiplication result shape:\", C.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w8rYObkabicO"
      },
      "source": [
        "\n",
        "\n",
        "> See! just like Numpy Arrays, but more powerful!\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UBOtVHO3WY_-"
      },
      "source": [
        "---\n",
        "## üìä **Data Representation in Deep Learning**\n",
        "\n",
        "The way data is represented depends on whether it is **structured (tabular)** or **unstructured (images)**.\n",
        "\n",
        "### üîπ1Ô∏è‚É£ **Tabular Data (Structured Data)**\n",
        "Tabular data consists of rows and columns.\n",
        "\n",
        "Each row represents a sample and each column represents a feature.\n",
        "\n",
        "- Represented as a **2D tensor**\n",
        "- Shape: `(batch_size, number_of_features)`\n",
        "- Commonly used for tasks like regression and classification\n",
        "\n",
        "Example:\n",
        "- Features: age, salary, debt  \n",
        "- Tensor shape: `(N, 3)`\n",
        "\n",
        "### üîπ2Ô∏è‚É£ **Image Data (Unstructured Data)**\n",
        "Image data is unstructured and contains spatial information.\n",
        "\n",
        "- Represented as a **4D tensor**\n",
        "- Shape: `(batch_size, channels, height, width)`\n",
        "- Channels represent color information:\n",
        "  - Grayscale ‚Üí 1 channel\n",
        "  - RGB ‚Üí 3 channels\n",
        "\n",
        "Example:\n",
        "- RGB image of size 224√ó224  \n",
        "- Tensor shape: `(N, 3, 224, 224)`\n",
        "\n",
        "\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "27NITm3aWla9"
      },
      "source": [
        "## üìå **How to Change Dimensions in PyTorch?**\n",
        "\n",
        "Manipulating tensor shapes is essential in deep learning. PyTorch provides several functions to modify tensor dimensions.\n",
        "\n",
        "### **üîπ 1Ô∏è‚É£ Flatten**\n",
        "- Converts **any shape** to `(batch_size, features)`.\n",
        "- **Example:**  \n",
        "  `(batch_size, channels, height, width) ‚Üí (batch_size, features)`\n",
        "\n",
        "### **üîπ 2Ô∏è‚É£ Squeeze**\n",
        "- **Removes dimensions** with size `1`.\n",
        "- **Example:**  \n",
        "  `(1, 32, 3, 28, 28) ‚Üí (32, 3, 28, 28)`\n",
        "\n",
        "### **üîπ 3Ô∏è‚É£ Unsqueeze**\n",
        "- **Adds a dimension** with size `1` at a specified position.\n",
        "- **Example:**  \n",
        "  `(3, 28, 28) ‚Üí (1, 3, 28, 28)`\n",
        "\n",
        "### **üîπ 4Ô∏è‚É£ View (works similar to reshape)**\n",
        "- **Reshapes a tensor freely** while maintaining the same number of elements.\n",
        "- **Example:**  \n",
        "  `(32, 3, 28, 28) ‚Üí view(-1, 3*28*28) ‚Üí (32, 3*28*28)`\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vY0z_-JwRYWk",
        "outputId": "62ea5007-df18-49a0-e551-fc2dbeff30db"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Flatten: torch.Size([32, 2352])\n",
            "Squeeze: torch.Size([3, 28, 28])\n",
            "Unsqueeze: torch.Size([1, 3, 28, 28])\n",
            "View: torch.Size([32, 2352])\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "# 1Ô∏è‚É£ Flatten - Convert any shape to (batch_size, features)\n",
        "x = torch.randn(32, 3, 28, 28)\n",
        "x_flat = x.flatten(start_dim=1)\n",
        "print(\"Flatten:\", x_flat.shape)  # (32, 2352)\n",
        "\n",
        "# 2Ô∏è‚É£ Squeeze - Remove dimensions with size 1\n",
        "x = torch.randn(1, 3, 28, 28)\n",
        "x_sq = x.squeeze()\n",
        "print(\"Squeeze:\", x_sq.shape)  # (3, 28, 28)\n",
        "\n",
        "# 3Ô∏è‚É£ Unsqueeze - Add a new dimension of size 1\n",
        "x = torch.randn(3, 28, 28)\n",
        "x_unsq = x.unsqueeze(0)\n",
        "print(\"Unsqueeze:\", x_unsq.shape)  # (1, 3, 28, 28)\n",
        "\n",
        "# 4Ô∏è‚É£ View - Reshape freely while keeping same number of elements\n",
        "x = torch.randn(32, 28, 28, 3)\n",
        "x_view = x.view(32, -1)  # Flatten all except batch\n",
        "print(\"View:\", x_view.shape)  # (32, 28*28*3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q98MVwNxvNwL"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YkrCEfnNborH"
      },
      "source": [
        "## üìå **Changing Data Type or Moving Data/Model to CPU/GPU**  \n",
        "\n",
        "PyTorch allows you to **change the datatype** of a tensor and **move it between CPU and GPU** using `.to()`.  \n",
        "\n",
        "\n",
        "### üîπ **Change Datatype**\n",
        "Use `.to(dtype)` to convert a tensor's data type."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qwAQnY7HWYlG",
        "outputId": "25a3c15e-15d9-47d9-a9e3-769ccb6691c3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.float32\n",
            "torch.float16\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "# Create a float32 tensor\n",
        "x = torch.tensor([1.2, 2.3, 3.4], dtype=torch.float32)\n",
        "print(x.dtype)  # Output: torch.float32\n",
        "\n",
        "# Convert to float16\n",
        "x_half = x.to(torch.float16)\n",
        "print(x_half.dtype)  # Output: torch.float16"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6MOJ8tx0ceVL"
      },
      "source": [
        "### üîπ **Move Tensors to GPU (if available)**\n",
        "**GPUs are faster and more efficient** in most cases when training or inferencing deep learning models.\n",
        "\n",
        "Use `.to(device)` to move a tensor to GPU for faster computation.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Iv00vultxnB",
        "outputId": "f92f78ab-82ca-487e-f2b9-ba7431a6bbd2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n"
          ]
        }
      ],
      "source": [
        "# Automatically select CPU or GPU\n",
        "device = torch.device(\"GPU\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Create a tensor and move it to GPU\n",
        "x_gpu = x.to(device)\n",
        "print(x_gpu.device)  # Output: cuda:0 (if GPU is available) or cpu"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aqEVOLXed3ut"
      },
      "source": [
        "Note: When training a model, always move BOTH the model and data to the same device. Otherwise, you will get an error like this:\n",
        "\n",
        "`RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!`\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O8DN_nVlUbod"
      },
      "source": [
        "## **üìå PyTorch Workflow Organization**\n",
        "\n",
        "### **It consists of 4 main components:**\n",
        "1Ô∏è‚É£ **Dataset Class**  \n",
        "- Handles loading and preprocessing data.  \n",
        "- Converts raw data (e.g., images, CSVs) into model-ready tensors.  \n",
        "\n",
        "2Ô∏è‚É£ **Model Class**  \n",
        "- Defines the architecture of your neural network (e.g., layers, activations).  \n",
        "\n",
        "3Ô∏è‚É£ **Training Loop**  \n",
        "- Updates model weights using backpropagation and optimizers.  \n",
        "- Computes the loss for every batch and adjusts the parameters to minimize it.  \n",
        "\n",
        "4Ô∏è‚É£ **Validation Loop**  \n",
        "- Evaluates the model's performance on a validation set.  \n",
        "- Does not update weights but computes metrics like accuracy or loss.  \n",
        "\n",
        "\n",
        "\n",
        "### **üìå Note:**\n",
        "All the labs will follow this structure. You will just modify the content for different tasks, such as changing datasets, architectures, or loss functions.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AXG9aSXCYaza"
      },
      "source": [
        "## 1Ô∏è‚É£ **Dataset Class**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gOwm0-zsulwK"
      },
      "source": [
        "In PyTorch, a **Dataset Class** is responsible for transforming raw data into samples that are ready to be used by a model.  \n",
        "Each sample returned consists of:\n",
        "- An **input** (features or image)\n",
        "- Its corresponding **label**  \n",
        "\n",
        "\n",
        "\n",
        "## üîπ For Tabular Data (Using `TensorDataset`)\n",
        "\n",
        "When working with **tabular data** (e.g., CSV files already converted to tensors), we can use\n",
        "`TensorDataset` to pair input features with their labels."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sNlgbwZPnD6H",
        "outputId": "a020ef3b-51b1-45db-b953-25055787a7e5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of one sample: torch.Size([30])\n"
          ]
        }
      ],
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from torch.utils.data import TensorDataset\n",
        "from torch.utils.data import DataLoader\n",
        "import torch\n",
        "\n",
        "# load data\n",
        "data = load_breast_cancer()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# Standardize the data\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# transform to tensors\n",
        "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
        "X_test  = torch.tensor(X_test, dtype=torch.float32)\n",
        "y_train = torch.tensor(y_train, dtype=torch.float32)\n",
        "y_test  = torch.tensor(y_test, dtype=torch.float32)\n",
        "\n",
        "# TensorDataset pairs input features (X) with their corresponding labels (y)\n",
        "# Each item in the dataset is returned as (X[i], y[i])\n",
        "train_dataset = TensorDataset(X_train, y_train)\n",
        "test_dataset = TensorDataset(X_test, y_test)\n",
        "\n",
        "# Access a single sample from the dataset\n",
        "# This helps verify the shape of one data sample\n",
        "first_sample, _ = train_dataset[0]\n",
        "print(f\"Shape of one sample: {first_sample.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZMPiHVpcxYt5"
      },
      "source": [
        "## üîπ For Image Data (Using Built-in Datasets)\n",
        "\n",
        "In PyTorch, image datasets can be:\n",
        "- **Built-in datasets** provided by PyTorch (e.g., MNIST, CIFAR-10)\n",
        "- **Custom datasets** created for data that is not provided in a ready-made format\n",
        "\n",
        "In **Stage 2**, we'll use **built-in datasets**\n",
        "\n",
        "In **Stage 3**, we'll create **custom Dataset classes** for our own image data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XCinzfXNyUON",
        "outputId": "2c5be8e5-dab9-474a-8989-10946e876815"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9.91M/9.91M [00:00<00:00, 35.3MB/s]\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 28.9k/28.9k [00:00<00:00, 1.02MB/s]\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1.65M/1.65M [00:00<00:00, 9.73MB/s]\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4.54k/4.54k [00:00<00:00, 5.71MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Image shape: torch.Size([1, 28, 28])\n",
            "Label: 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "from torchvision.datasets import MNIST\n",
        "from torchvision.transforms.functional import to_tensor\n",
        "\n",
        "# Training dataset\n",
        "train_dataset = MNIST(\n",
        "    root='./datasets',     # Dataset storage path\n",
        "    train=True,            # Use training data\n",
        "    transform=to_tensor,   # Convert images to tensors\n",
        "    download=True          # Download if not available\n",
        ")\n",
        "\n",
        "# Testing dataset\n",
        "test_dataset = MNIST(\n",
        "    root='./datasets',     # Dataset storage path\n",
        "    train=False,           # Use test data\n",
        "    transform=to_tensor,   # Convert images to tensors\n",
        "    download=True          # Download if not available\n",
        ")\n",
        "\n",
        "# print one sample from the dataset\n",
        "# Each sample consists of an image tensor and its label\n",
        "sample_image, sample_label = train_dataset[0]\n",
        "\n",
        "print(f\"\\n Image shape: {sample_image.shape}\")  # (1, 28, 28)\n",
        "print(f\"Label: {sample_label}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6O5WZp8HJ6fK"
      },
      "source": [
        "\n",
        "Right now, our **Dataset Class** loads **one sample at a time** when we call:\n",
        "```python\n",
        "sample_image, sample_label = train_dataset[0]  # Loads only one sample\n",
        "```\n",
        "‚úÖ **That‚Äôs great for understanding**, but when training a model, we need to process **multiple samples at once** for efficiency.\n",
        "\n",
        "‚ùå **Problem**: We need batches, not single samples.  \n",
        "‚úÖ **Solution**: We use `DataLoader` to handle batching automatically."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6CEW3kknM6t3"
      },
      "source": [
        "## üìå **What are DataLoaders ?**\n",
        "\n",
        "<img src=\"https://i.imgur.com/aHE3lnE.png\" width=\"70%\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E8GKnrdjFPtH"
      },
      "source": [
        "\n",
        "A **DataLoader** is a PyTorch utility that takes a Dataset and does:\n",
        "- **Batching**: Groups multiple samples together for faster processing.\n",
        "- **Shuffling**: Randomizes data order to improve training.\n",
        "- **Multi-threading**: Loads data efficiently in parallel.\n",
        "\n",
        "| **Argument**     | **Description** |\n",
        "|-----------------|---------------|\n",
        "| `dataset` | The dataset object (e.g., `train_dataset`) |\n",
        "| `batch_size` | Number of samples per batch (e.g., `32`) |\n",
        "| `shuffle` | Whether to **randomly shuffle** data each epoch (`True` = better for training) |\n",
        "| `num_workers` | Number of parallel **CPU workers** to load data faster |\n",
        "| `collate_fn` | A function to **customize how data is stacked** (useful when data has variable sizes) |\\"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qivcbu_CNXfh",
        "outputId": "90da363b-e110-4b5e-ffd0-67870954016b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training batch input shape: torch.Size([32, 1, 28, 28])\n",
            "Training batch labels shape: torch.Size([32])\n"
          ]
        }
      ],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# DataLoader for training data\n",
        "train_loader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=32,\n",
        "    shuffle=True,\n",
        "    num_workers=2\n",
        ")\n",
        "# DataLoader for test/validation data\n",
        "test_loader = DataLoader(\n",
        "    test_dataset,\n",
        "    batch_size=32,\n",
        "    shuffle=False,\n",
        "    num_workers=2\n",
        ")\n",
        "# Get the first batch from the training DataLoader\n",
        "X_batch, y_batch = next(iter(train_loader))\n",
        "print(f\"Training batch input shape: {X_batch.shape}\")\n",
        "print(f\"Training batch labels shape: {y_batch.shape}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ApKlCp-MvZVt"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XU57FGt_Ykoj"
      },
      "source": [
        "## 2Ô∏è‚É£ **Model Class**\n",
        "\n",
        "In PyTorch, `nn.Linear(in_features, out_features)`\n",
        "\n",
        "creates a **fully connected (dense) layer** that applies a linear transformation:\n",
        "\n",
        "$y = xW^T + b$\n",
        "\n",
        "\n",
        "- **`in_features`**: number of input features  \n",
        "- **`out_features`**: number of neurons (outputs) in the layer  \n",
        "- The layer automatically creates learnable **weights** and **bias**.\n",
        "\n",
        "‚úÖ Example: a layer that takes 3 input features and outputs 1 value:\n",
        "\n",
        "\n",
        "\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c42PESt1sUw0",
        "outputId": "967d3693-6aea-4044-db9e-8520e70c5832"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input shape: torch.Size([4, 3])\n",
            "Output shape: torch.Size([4, 1])\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# Create a linear layer: 3 input features -> 1 output\n",
        "linear = nn.Linear(in_features=3, out_features=1)\n",
        "\n",
        "# Example input: batch of 4 samples, each with 3 features\n",
        "x = torch.randn(4, 3)\n",
        "\n",
        "# Forward through the layer\n",
        "y = linear(x)\n",
        "\n",
        "print(\"Input shape:\", x.shape)   # torch.Size([4, 3])\n",
        "print(\"Output shape:\", y.shape)  # torch.Size([4, 1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PNCHp3ihvl6s"
      },
      "source": [
        "### **üìå Key Components of Model Class:**\n",
        "####1Ô∏è‚É£ **Define Layers (`__init__` method):**  \n",
        "\n",
        "Inside the `__init__` method, we define **what the neural network looks like**. This includes:\n",
        "\n",
        "- **Number of layers**  \n",
        "  How many linear (`nn.Linear`) layers the model has (depth of the network).\n",
        "\n",
        "- **Hidden layer sizes**  \n",
        "  How many neurons each hidden layer contains.\n",
        "\n",
        "- **Activation functions**  \n",
        "  Activation functions introduce **non-linearity**, allowing the network to learn complex patterns.\n",
        "  - Common choice for hidden layers: **ReLU**\n",
        "\n",
        "- **Output activation function**  \n",
        "  The activation used at the final layer depends on the task:\n",
        "  - **Binary classification** ‚Üí `Sigmoid`\n",
        "  - **Multiclass classification** ‚Üí `Softmax`\n",
        "  - **Regression** ‚Üí No activation (linear output)\n",
        "\n",
        "üìå **Important:**  \n",
        "Hidden layers usually use ReLU, while the **output layer activation is task-dependent**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dWfyCtXWsTgF"
      },
      "source": [
        "#### 2Ô∏è‚É£ **Forward Pass (`forward` method):**\n",
        "\n",
        "The `forward()` method defines **how the input data flows through the model** to produce the final output.\n",
        "\n",
        "- The input tensor is passed through each layer **in order**.\n",
        "- Activation functions are applied after linear layers to introduce **non-linearity**.\n",
        "- The final layer produces the model‚Äôs prediction.\n",
        "\n",
        "üìå **Note:**  \n",
        "During training, PyTorch automatically tracks all operations in the `forward()` method to compute gradients during backpropagation.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tk6qfrKJK88F"
      },
      "source": [
        "‚úÖ **Example: One neural network layer**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gmUbfIKiZc8X"
      },
      "source": [
        "\n",
        "<img src=\"https://miro.medium.com/v2/resize:fit:1100/format:webp/1*IAkZWzDOYGaiu3e47rEMgQ.png\" width=\"60%\">\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "Opi3_J4dE_pT"
      },
      "outputs": [],
      "source": [
        "class NN1Layer(nn.Module):\n",
        "\n",
        "  def __init__(self, input_dim):\n",
        "\n",
        "    super(NN1Layer, self).__init__()\n",
        "    # input_dim = num of features, Output for binary classification is 1\n",
        "    self.layer_1 = nn.Linear(input_dim, 1)\n",
        "\n",
        "    # output activation function\n",
        "    self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "  # forward pass\n",
        "  def forward(self, x):\n",
        "    z = self.layer_1(x)\n",
        "    a = self.sigmoid(z)\n",
        "    return a"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pLXie4eWLSjd"
      },
      "source": [
        "‚úÖ **Example: Two neural network layers**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uLPIVOoIhOhv"
      },
      "source": [
        "\n",
        "<img src=\"https://miro.medium.com/v2/0*GZrkL6Lqt9dIAJ61.jpg\" width=\"60%\">"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "87V4-6vDFxlM"
      },
      "outputs": [],
      "source": [
        "class NN2Layer(nn.Module):\n",
        "\n",
        "    def __init__(self, input_dim, hidden_dim):\n",
        "\n",
        "        super(NN2Layer, self).__init__() # contruct, show the arcitecture\n",
        "        # input_dim = num of features, hidden_dim = num of neurons\n",
        "        self.layer1 = nn.Linear(input_dim, hidden_dim) #this does the trasnformation\n",
        "        # hidden_dim = num of neurons, Output for binary classification is 1\n",
        "        self.layer2 = nn.Linear(hidden_dim, 1)\n",
        "\n",
        "        # non-linearity activation function\n",
        "        self.relu = nn.ReLU()\n",
        "        # output activation function\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    # forward pass\n",
        "    def forward(self, x):\n",
        "        z1 = self.layer1(x)\n",
        "        a1 = self.relu(z1)\n",
        "        z2 = self.layer2(a1)\n",
        "        a2 = self.sigmoid(z2)\n",
        "        return a2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "slEZs4vBe1dJ"
      },
      "source": [
        "\n",
        "\n",
        "> We can instantiate the model and print it to see the architecture, layers, and total number of trainable parameters.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OKrJiWQTdgYZ",
        "outputId": "f1b04a86-2c5e-45ad-ccd7-437de2db3b99"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Architecture:\n",
            "\n",
            "NN2Layer(\n",
            "  (layer1): Linear(in_features=4, out_features=3, bias=True)\n",
            "  (layer2): Linear(in_features=3, out_features=1, bias=True)\n",
            "  (relu): ReLU()\n",
            "  (sigmoid): Sigmoid()\n",
            ")\n",
            "\n",
            "Total trainable parameters: 19\n"
          ]
        }
      ],
      "source": [
        "# Instantiate the model\n",
        "input_dim = 4     # number of input features\n",
        "hidden_dim = 3    # number of hidden neurons\n",
        "\n",
        "model = NN2Layer(input_dim, hidden_dim)\n",
        "\n",
        "# Print the model architecture\n",
        "print(\"Model Architecture:\\n\")\n",
        "print(model)\n",
        "\n",
        "# Calculate the total number of trainable parameters\n",
        "total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f\"\\nTotal trainable parameters: {total_params}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "naYO9UOyvWYR"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o42xnLsEYr8D"
      },
      "source": [
        "## 3Ô∏è‚É£ **Training Loop**\n",
        "\n",
        "The **training loop** is responsible for **updating the model's weights** so that it learns to minimize the loss function.\n",
        "\n",
        "### üß© **Parameters**\n",
        "\n",
        "- **`model`** ‚Äì The neural network to be trained.  \n",
        "- **`optimizer`** ‚Äì Updates model parameters (e.g., SGD, Adam).  \n",
        "- **`criterion`** ‚Äì Loss function, depends on the task.  \n",
        "- **`train_loader`** ‚Äì PyTorch `DataLoader` that provides batches of training data.  \n",
        "- **`device`** ‚Äì Device used for computation (`cpu` or `cuda`).\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "hfanJzrdnFA_"
      },
      "outputs": [],
      "source": [
        "def train_one_epoch(model, optimizer, criterion, train_loader, device):\n",
        "    # Set the model to training mode\n",
        "    model.train()\n",
        "\n",
        "    running_loss = 0.0\n",
        "\n",
        "    for X_batch, y_batch in train_loader:\n",
        "        # Move batch to the selected device so it can work on cpu or gpu\n",
        "        X_batch = X_batch.to(device)\n",
        "        y_batch = y_batch.view(-1, 1).to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(X_batch)\n",
        "        loss = criterion(outputs, y_batch)\n",
        "\n",
        "        # Backward pass & optimization\n",
        "        optimizer.zero_grad()   # Clear previous gradients\n",
        "        loss.backward()         # Compute gradients\n",
        "        optimizer.step()        # Update model parameters\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    # Average loss over all batches\n",
        "    avg_loss = running_loss / len(train_loader)\n",
        "\n",
        "    return avg_loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3FYUwAxlpXzY"
      },
      "source": [
        "###üìå **For criterions (Loss Functions)**:\n",
        "Different tasks require different loss functions\n",
        "- Linear Regression ‚Üí `nn.MSELoss()`  \n",
        "- Binary classification ‚Üí `nn.BCELoss()`  \n",
        "- Multiclass classification ‚Üí `nn.CrossEntropyLoss()`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hDYXDDeNqwCY"
      },
      "source": [
        "####1Ô∏è‚É£ `nn.MSELoss()`\n",
        "- `MSELoss` expects **continuous values** (regression).\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SDWNgCK2sCDo",
        "outputId": "9f7902e0-336a-4aa7-8163-2c4fbb8aa0bc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE Loss: 0.25\n"
          ]
        }
      ],
      "source": [
        "# Example predictions and targets\n",
        "y_pred = torch.tensor([[2.5], [3.0], [4.5]])\n",
        "y_true = torch.tensor([[3.0], [2.5], [5.0]])\n",
        "\n",
        "criterion = nn.MSELoss()\n",
        "loss = criterion(y_pred, y_true)\n",
        "print(\"MSE Loss:\", loss.item())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L9OMs--Rs4Jk"
      },
      "source": [
        "####2Ô∏è‚É£ `nn.BCELoss()`\n",
        "- `BCELoss` expects **probabilities** between 0 and 1.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p0lNu1qss7rz",
        "outputId": "6ea508ff-9399-4cd3-b45f-e815087a5426"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Binary Cross Entropy Loss: 0.36354804039001465\n"
          ]
        }
      ],
      "source": [
        "# Predicted probabilities (after sigmoid)\n",
        "y_pred = torch.tensor([[0.8], [0.3], [0.6]])\n",
        "y_true = torch.tensor([[1.0], [0.0], [1.0]])\n",
        "\n",
        "criterion = nn.BCELoss()\n",
        "loss = criterion(y_pred, y_true)\n",
        "print(\"Binary Cross Entropy Loss:\", loss.item())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cr8bgGs6tFJi"
      },
      "source": [
        "####3Ô∏è‚É£ `nn.CrossEntropyLoss()`\n",
        "- `CrossEntropyLoss` expects **raw logits** (no Softmax needed).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uaba4iKbta-I",
        "outputId": "8318326d-95a2-4642-88c5-12b6db114a98"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cross Entropy Loss: 0.450598806142807\n"
          ]
        }
      ],
      "source": [
        "# Raw model outputs (logits), shape: (batch_size, num_classes)\n",
        "logits = torch.tensor([\n",
        "    [2.0, 0.5, 1.0],\n",
        "    [0.1, 1.5, 0.3]\n",
        "])\n",
        "# True class indices\n",
        "targets = torch.tensor([0, 1])\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "loss = criterion(logits, targets)\n",
        "print(\"Cross Entropy Loss:\", loss.item())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5UlJgjmKvjbp"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Isn-l9gYyfT"
      },
      "source": [
        "\n",
        "## 4Ô∏è‚É£ **Validation Loop**\n",
        "\n",
        "The **validation loop** evaluates the model‚Äôs performance on unseen data **without updating the weights**.\n",
        "\n",
        "It is used to measure how well the model generalizes.\n",
        "\n",
        "### üß© Parameters\n",
        "\n",
        "- **`model`** ‚Äì The trained neural network to be evaluated.  \n",
        "- **`criterion`** ‚Äì Loss function used for evaluation\n",
        "- **`test_loader`** ‚Äì PyTorch `DataLoader` that provides batches of validation/test data.  \n",
        "- **`device`** ‚Äì Device used for computation (`cpu` or `cuda`).  \n",
        "\n",
        "\n",
        "üìå **Note:**  \n",
        "Gradients are disabled during validation using `torch.no_grad()` to improve efficiency and prevent weight updates.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "pxMyr159d5UW"
      },
      "outputs": [],
      "source": [
        "def validate(model, criterion, test_loader, device): #####very copy pastable ########*\n",
        "    # Set the model to evaluation mode **\n",
        "    model.eval()\n",
        "\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0 #num of samples\n",
        "\n",
        "    with torch.no_grad():  # Disable gradient computation, doesnt zero it out ///\n",
        "        for X_batch, y_batch in test_loader:\n",
        "            # Move batch to the selected device\n",
        "            X_batch = X_batch.to(device)\n",
        "            y_batch = y_batch.view(-1, 1).to(device)\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(X_batch)\n",
        "            loss = criterion(outputs, y_batch)\n",
        "            running_loss += loss.item() #append loss to running loss\n",
        "\n",
        "            # Binary predictions\n",
        "            predicted = (outputs > 0.5).float()\n",
        "\n",
        "            # Accuracy calculation\n",
        "            correct += (predicted == y_batch).sum().item()\n",
        "            total += y_batch.size(0)\n",
        "\n",
        "    avg_loss = running_loss / len(test_loader)\n",
        "    accuracy = correct / total\n",
        "\n",
        "    return avg_loss, accuracy\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_bcKsHoLvTxk"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bkoj068knVPN"
      },
      "source": [
        "## **üìå Full Training Process in PyTorch**\n",
        "\n",
        "Now that you understand the **Dataset Class, Model Class, Training Loop, and Validation Loop**, it's time to put everything together into a **full training process**.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YUK2taqBkUyR"
      },
      "source": [
        "### Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "zryj9VCzkaHl"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.optim import Adam\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from torch.utils.data import TensorDataset\n",
        "from torch.utils.data import DataLoader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TOguR6wwkmlr"
      },
      "source": [
        "### Prepare Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "BT-TaJLL6isg"
      },
      "outputs": [],
      "source": [
        "data = load_breast_cancer()\n",
        "\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y) #strasufy to be evenly distribured\n",
        "\n",
        "# Standardize the data\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# transform to tensors\n",
        "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
        "X_test  = torch.tensor(X_test, dtype=torch.float32)\n",
        "y_train = torch.tensor(y_train, dtype=torch.float32)\n",
        "y_test  = torch.tensor(y_test, dtype=torch.float32)\n",
        "\n",
        "# Create TensorDatasets for training and testing, it mappes the samples to their labels\n",
        "train_dataset = TensorDataset(X_train, y_train)\n",
        "test_dataset = TensorDataset(X_test, y_test)\n",
        "\n",
        "# Create Dataloaders to train and test data in batches\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True) #shuffle the\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False) # no shuffle in the test !!!!!!!!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P_Y-oPSxlJOw"
      },
      "source": [
        "### Run full training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XIgTf7gdlOQZ",
        "outputId": "93b49c0f-062b-4c61-db40-7ffd6680a581"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cpu\n",
            "Starting Training...\n",
            "Epoch [5/50], Train Loss: 0.4292, Val Loss: 0.3972, Val Accuracy: 0.9123\n",
            "Epoch [10/50], Train Loss: 0.2121, Val Loss: 0.2247, Val Accuracy: 0.9298\n",
            "Epoch [15/50], Train Loss: 0.1377, Val Loss: 0.1624, Val Accuracy: 0.9298\n",
            "Epoch [20/50], Train Loss: 0.1095, Val Loss: 0.1320, Val Accuracy: 0.9474\n",
            "Epoch [25/50], Train Loss: 0.0855, Val Loss: 0.1151, Val Accuracy: 0.9474\n",
            "Epoch [30/50], Train Loss: 0.0789, Val Loss: 0.1056, Val Accuracy: 0.9474\n",
            "Epoch [35/50], Train Loss: 0.0677, Val Loss: 0.1007, Val Accuracy: 0.9561\n",
            "Epoch [40/50], Train Loss: 0.0614, Val Loss: 0.0973, Val Accuracy: 0.9561\n",
            "Epoch [45/50], Train Loss: 0.0568, Val Loss: 0.0933, Val Accuracy: 0.9649\n",
            "Epoch [50/50], Train Loss: 0.0561, Val Loss: 0.0899, Val Accuracy: 0.9649\n",
            "Training Complete!\n"
          ]
        }
      ],
      "source": [
        "# Device configuration\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "num_epochs = 50\n",
        "learning_rate = 0.001\n",
        "\n",
        "# Model, Criterion, Optimizer\n",
        "input_dim = X_train.shape[1]\n",
        "hidden_dim = 10\n",
        "model =NN2Layer(input_dim, hidden_dim).to(device)\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "\n",
        "# Run Training\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "val_accuracies = []\n",
        "\n",
        "print('Starting Training...')\n",
        "for epoch in range(num_epochs):\n",
        "    # Train one epoch\n",
        "    train_loss = train_one_epoch(model, optimizer, criterion, train_loader, device)\n",
        "\n",
        "    # Validate\n",
        "    val_loss, val_accuracy = validate(model, criterion, test_loader, device)\n",
        "\n",
        "    train_losses.append(train_loss)\n",
        "    val_losses.append(val_loss)\n",
        "    val_accuracies.append(val_accuracy)\n",
        "\n",
        "    if (epoch + 1) % 5 == 0:\n",
        "        print(f'Epoch [{epoch+1}/{num_epochs}], Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.4f}')\n",
        "\n",
        "print('Training Complete!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LvvMxHD4nfTs"
      },
      "source": [
        "### Plot losses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 507
        },
        "id": "1ftDlPPhniA6",
        "outputId": "5d295b26-f531-43d8-c686-679a3a3e859e"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 700x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Plotting results,,,copy paste to make life easier\n",
        "plt.figure(figsize=(7, 5))\n",
        "\n",
        "plt.plot(train_losses, label='Train Loss')\n",
        "plt.plot(val_losses, label='Validation Loss')\n",
        "plt.title('Loss over Epochs')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XdvSQimxq_3O"
      },
      "source": [
        "## Now you know how to use PyTorch for NNs :)\n",
        "\n",
        "\n",
        "![image.png](https://i.imgur.com/1xbDOQX.jpeg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pDl5V6-7SOal"
      },
      "source": [
        "### **Contributed by: Yara Alzahrani, Mohamed Eltayeb**"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}